# ğŸš€ ai-instant-ngp

Neural Radiance Field (NeRF) trainer based on NVIDIAâ€™s [Instantâ€‘NGP](https://github.com/NVlabs/instant-ngp), CUDAâ€‘optimized and containerâ€‘ready for Kubernetes deployment. Includes a full NeRF training pipeline plus FastSRâ€‘NeRF (lowâ€‘res NeRF + superâ€‘resolution).

## ğŸ”§ Requirements

* Docker with NVIDIA runtime  
* CUDAÂ 12.9+  
* Compatible GPU  
* KubernetesÂ +Â Argoâ€¯CD (for deployment)  
* Local container registry (default: `localhost:5000`)

## ğŸ“¦ Project Layout

```
ai-instant-ngp/
â”œâ”€â”€ Dockerfile          # CUDA image with all deps
â”œâ”€â”€ Makefile            # Build & deploy scripts
â”œâ”€â”€ Jenkinsfile         # CI/CD pipeline
â”œâ”€â”€ entrypoint.sh       # Container entry script
â”œâ”€â”€ train_ngp.py        # NeRF training
â”œâ”€â”€ render_pairs.py     # Generate LR/HR pairs
â””â”€â”€ train_sr.py         # Superâ€‘resolution training
```

## ğŸ¤– Training Pipeline

The complete process has three phases:

### 1. NeRF Training (`train_ngp.py`)
```bash
python3 train_ngp.py   --data /path/scene   --transforms transforms.json   --steps 15000   --snapshot model.ingp
```

### 2. LR/HR Pair Generation (`render_pairs.py`)
```bash
python3 render_pairs.py   --snapshot model.ingp   --out /path/scene   --lr 960 540   --factor 2
```
Creates  
* `renders_lr/` â€“ lowâ€‘res renders  
* `renders_hr/` â€“ highâ€‘res renders

### 3. Superâ€‘Resolution Training (`train_sr.py`)
```bash
python3 train_sr.py   --lr_dir /path/scene/renders_lr   --hr_dir /path/scene/renders_hr   --out sr_model.pth   --scale 2
```

## ğŸ”„ CI/CD Pipeline

`Jenkinsfile` automates:

1. **Build & Test**  
   * Build Docker image  
   * Integration tests  
   * Push to registry
2. **Argoâ€¯CD Deploy**
   ```yaml
   # Helm values.yaml
   job:
     image:
       repository: localhost:5000/nerf-trainer
       tag: v0.1.0
     resources:
       limits:
         nvidia.com/gpu: 1
       requests:
         cpu: 500m
         memory: 4Gi
     volume:
       pvcName: pvc-nerf-data
       mountPath: /data

   training:
     steps: 15000
     superResolution:
       enabled: true
       scale: 2
       resolution:
         width: 960
         height: 540
   ```

### Job Highlights
* Restart policy: **Never**  
* Endâ€‘toâ€‘end NeRFÂ +Â SR inside the Job  
* GPU via `nvidia-device-plugin`  
* Resourceâ€‘optimized for training

### ğŸ“ Dataset Layout
```
/data/my-scene/
â”œâ”€â”€ input/
â”‚   â”œâ”€â”€ transforms.json   # Camera params (from COLMAP)
â”‚   â””â”€â”€ images/
â”‚       â”œâ”€â”€ 000.jpg
â”‚       â””â”€â”€ ...
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ nerf.ingp         # Trained NeRF
â”‚   â””â”€â”€ sr_x2.pth         # Superâ€‘resolution model
â””â”€â”€ renders/
    â”œâ”€â”€ lr/               # Lowâ€‘res renders
    â””â”€â”€ hr/               # Highâ€‘res renders
```

## â˜ï¸ Kubernetes Deployment

```bash
# Build, push and deploy
make release

# Patch Helm values only
make update-values

# Force sync in ArgoÂ CD
make sync
```

## ğŸ”„ Release Pipeline

1. Build CUDA image  
2. Push to container registry  
3. Update Helm chart values  
4. Sync deployment through Argoâ€¯CD

## ğŸ“Š Monitoring

### Metrics
* **NeRF Training**
  * Training loss
  * PSNR
  * GPU/VRAM usage
  * Iteration time
* **Superâ€‘Resolution**
  * L1/L2 loss
  * PSNR/SSIM per image
  * Perceptual quality scores

### Interfaces
* ArgoÂ CD dashboard (Job progress)
* PrometheusÂ +Â Grafana (GPU metrics)
* Structured Kubernetes logs

## ğŸ” Troubleshooting

| Issue | Fix |
|-------|-----|
| **GPU error**<br>`no NVIDIA GPU device is present` | Check `nvidia-device-plugin`, free GPU memory, validate CUDA version |
| **Training OOM**<br>`CUDA out of memory` | Lower training resolution, reduce batch size, monitor VRAM |
| **SR mismatch**<br>`Mismatch in image pairs` | Verify scale factor, check renders integrity, validate LR/HR resolutions |
